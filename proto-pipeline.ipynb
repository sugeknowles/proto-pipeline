{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65e22bb-254b-4748-9e5b-62f2832b5687",
   "metadata": {},
   "source": [
    "# Install KFP and db_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c930060-8079-4626-a955-2e775f586c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "!pip3 install {USER_FLAG} kfp==1.8.9 > /dev/null\n",
    "!pip3 install {USER_FLAG} db_dtypes > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b482f-9869-455a-9be6-70f6a107889c",
   "metadata": {},
   "source": [
    "# Restart notebook kernel to load new modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9c99-beb8-4190-93bd-4368a4fd589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5149044d-26c4-4e06-afbb-b821a5c33688",
   "metadata": {},
   "source": [
    "## Validate KFP Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64943754-f62f-4be3-9792-38fd318c0f3c",
   "metadata": {},
   "source": [
    "# Set environment variables for PROJECT_ID and BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d4cd7-c59c-4c35-b67b-a466f85e4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # Reimport due to kernel restart\n",
    "\n",
    "PROJECT_ID = \"\"\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(f\"Project ID: {PROJECT_ID}\")\n",
    "    \n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "print(f\"Bucket Name: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff6f7f-cff3-4c75-918a-0e970e46ca00",
   "metadata": {},
   "source": [
    "# Set environment variables for PATH, REGION & PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187523da-24e5-44b1-89b3-b9d22e090a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322e90c-5497-4e56-b667-f18c053d8d36",
   "metadata": {},
   "source": [
    "# LAB BEGINS HERE\n",
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d571af-f276-4878-bda4-0425ff59fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import aiplatform_v1\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b05ce5-0119-4025-9717-e7a852d7b95a",
   "metadata": {},
   "source": [
    "# Pipeline Step 1:  [Component] Load data from BQ\n",
    "- Extracts training data from BQ table referenced as input to component\n",
    "- Loads data into Dataframe\n",
    "- Outputs data from component as CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497743d-f8ab-4d27-95c4-491ceb810857",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db_dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    # output_component_file=\"create_dataset.yaml\"\n",
    "    )\n",
    "def get_dataframe(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "    ):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    bqclient = bigquery.Client(project=\"#PROJECT_ID HERE\")\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad76fec-c872-4381-850d-25fdac8eebb0",
   "metadata": {},
   "source": [
    "# Pipeline Step 2:  [Component] Train Scikit-learn model\n",
    "- Takes CSV data from step 1 as input\n",
    "- Train Scikit-learn decision tree model\n",
    "- Output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6183165-3abe-4928-8b54-28016f330838",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"beans_model_component.yaml\",\n",
    ")\n",
    "def sklearn_train(\n",
    "    dataset: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(dataset.path)\n",
    "    labels = df.pop(\"Class\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "    skmodel = DecisionTreeClassifier()\n",
    "    skmodel.fit(x_train,y_train)\n",
    "    score = skmodel.score(x_test,y_test)\n",
    "    print('accuracy is:',score)\n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "    dump(skmodel, model.path + \".joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a65c4e-3a22-4c29-849c-dcd9a5890c8d",
   "metadata": {},
   "source": [
    "# Pipeline Step 3:  [Component] Upload & Deploy model to Vertex AI\n",
    "- Takes model from step 2 as input\n",
    "- Upload model to Vertex AI\n",
    "- Deploy model as Vertex AI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f993c9-dec1-4493-ab91-05ddbb022804",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"beans_deploy_component.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"beans-model-pipeline\",\n",
    "        artifact_uri = model.uri.replace(\"model\", \"\"),\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78976e47-291c-4660-907d-19ff15e42da8",
   "metadata": {},
   "source": [
    "# Pipeline Creation\n",
    "## Define a pipeline from the 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9268c43-0974-43d4-8202-64a62e4462f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"mlmd-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    dataset_task = get_dataframe(bq_table)\n",
    "    model_task = sklearn_train(\n",
    "        dataset_task.output\n",
    "    )\n",
    "    deploy_task = deploy_model(\n",
    "        model=model_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195d9da-b44a-4994-9407-6ef290320a10",
   "metadata": {},
   "source": [
    "## Compile pipeline to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6492e-3bf7-499d-a55f-e25ae537116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"mlmd_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee694b-0a2b-4696-9566-c7c1fb194e2a",
   "metadata": {},
   "source": [
    "# Execute Pipeline Runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b3bd1-6157-442f-a3fa-78c5aa693a3b",
   "metadata": {},
   "source": [
    "## Create Pipeline Job 1: Small Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5fa22-df08-48f9-86b9-18f1f2d824e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run1 = aiplatform.PipelineJob(\n",
    "    display_name=\"mlmd-pipeline\",\n",
    "    template_path=\"mlmd_pipeline.json\",\n",
    "    job_id=\"mlmd-pipeline-small-{0}\".format(timestamp),\n",
    "    parameter_values={\"bq_table\":\"{0}.beans.dry_bean_tbl_small\".format(PROJECT_ID)},\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734541d-34f9-4932-bb23-309b4ee2a059",
   "metadata": {},
   "source": [
    "## Create Pipeline Job 2:  Full Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ad9ed-3006-44b5-a7e8-ed6f555fec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "run2 = aiplatform.PipelineJob(\n",
    "    display_name=\"mlmd-pipeline\",\n",
    "    template_path=\"mlmd_pipeline.json\",\n",
    "    job_id=\"mlmd-pipeline-large-{0}\".format(timestamp),\n",
    "    parameter_values={\"bq_table\":\"{0}.beans.dry_bean_tbl\".format(PROJECT_ID)},\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990cf78-37d0-4922-be24-e087e470d23c",
   "metadata": {},
   "source": [
    "## Execute Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fca55f-c90e-4fed-8713-0b4cbb15deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.submit()\n",
    "#run2.submit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da1518-e77e-419c-ab69-36fb2f6f3a88",
   "metadata": {},
   "source": [
    "# Comparing pipeline runs with the Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5077c-accc-4279-9466-226413c0d4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aiplatform.get_pipeline_df(pipeline=\"mlmd-pipeline\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1329115-bd6e-46c8-80af-1876e0b1b162",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"metric.dataset_size\"], df[\"metric.accuracy\"],label=\"Accuracy\")\n",
    "plt.title(\"Accuracy and dataset size\")\n",
    "plt.legend(loc=4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435d908-6c73-4398-8078-198e5ed03143",
   "metadata": {},
   "source": [
    "## Querying Pipeline Metrics\n",
    "Getting all Model artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa77f3f-6e11-4b2d-85c8-82d9c2ed1b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "metadata_client = aiplatform_v1.MetadataServiceClient(\n",
    "  client_options={\n",
    "      \"api_endpoint\": API_ENDPOINT\n",
    "  }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a38a84-6221-4ec9-8351-24ac936474e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILTER=\"schema_title = \\\"system.Model\\\"\"\n",
    "artifact_request = aiplatform_v1.ListArtifactsRequest(\n",
    "    parent=\"projects/{0}/locations/{1}/metadataStores/default\".format(PROJECT_ID, REGION),\n",
    "    filter=MODEL_FILTER\n",
    ")\n",
    "model_artifacts = metadata_client.list_artifacts(artifact_request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301734ad-babe-4056-b46b-4307622df519",
   "metadata": {},
   "source": [
    "## Filtering objects and displaying in a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f89ed-078f-467e-9a72-5d53091cf8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIVE_FILTER = \"create_time > \\\"2021-08-10T00:00:00-00:00\\\" AND state = LIVE\"\n",
    "artifact_req = {\n",
    "    \"parent\": \"projects/{0}/locations/{1}/metadataStores/default\".format(PROJECT_ID, REGION),\n",
    "    \"filter\": LIVE_FILTER\n",
    "}\n",
    "live_artifacts = metadata_client.list_artifacts(artifact_req)\n",
    "\n",
    "# Display data in Dataframe\n",
    "data = {'uri': [], 'createTime': [], 'type': []}\n",
    "for i in live_artifacts:\n",
    "    data['uri'].append(i.uri)\n",
    "    data['createTime'].append(i.create_time)\n",
    "    data['type'].append(i.schema_title)\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
