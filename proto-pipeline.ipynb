{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65e22bb-254b-4748-9e5b-62f2832b5687",
   "metadata": {},
   "source": [
    "# Install KFP and db_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c930060-8079-4626-a955-2e775f586c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_FLAG = \"--user\"\n",
    "!pip3 install {USER_FLAG} kfp==1.8.9\n",
    "!pip3 install {USER_FLAG} db_dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "042b482f-9869-455a-9be6-70f6a107889c",
   "metadata": {},
   "source": [
    "# Restart notebook kernel to load new modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cae9c99-beb8-4190-93bd-4368a4fd589b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    # Automatically restart kernel after installs\n",
    "    import IPython\n",
    "    app = IPython.Application.instance()\n",
    "    app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64943754-f62f-4be3-9792-38fd318c0f3c",
   "metadata": {},
   "source": [
    "# Set environment variables for PROJECT_ID and BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d4cd7-c59c-4c35-b67b-a466f85e4c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = \"\"\n",
    "# Get your Google Cloud project ID from gcloud\n",
    "if not os.getenv(\"IS_TESTING\"):\n",
    "    shell_output=!gcloud config list --format 'value(core.project)' 2>/dev/null\n",
    "    PROJECT_ID = shell_output[0]\n",
    "    print(f\"Project ID: {PROJECT_ID}\")\n",
    "    \n",
    "BUCKET_NAME=\"gs://\" + PROJECT_ID + \"-bucket\"\n",
    "print(f\"Bucket Name: {BUCKET_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ff6f7f-cff3-4c75-918a-0e970e46ca00",
   "metadata": {},
   "source": [
    "# Set environment variables for PATH, REGION & PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187523da-24e5-44b1-89b3-b9d22e090a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin\n",
    "REGION=\"us-central1\"\n",
    "PIPELINE_ROOT = f\"{BUCKET_NAME}/pipeline_root/\"\n",
    "PIPELINE_ROOT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f322e90c-5497-4e56-b667-f18c053d8d36",
   "metadata": {},
   "source": [
    "# LAB BEGINS HERE\n",
    "Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d571af-f276-4878-bda4-0425ff59fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from kfp.v2 import compiler, dsl\n",
    "from kfp.v2.dsl import pipeline, component, Artifact, Dataset, Input, Metrics, Model, Output, InputPath, OutputPath\n",
    "from google.cloud import aiplatform\n",
    "# We'll use this namespace for metadata querying\n",
    "from google.cloud import aiplatform_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b05ce5-0119-4025-9717-e7a852d7b95a",
   "metadata": {},
   "source": [
    "# Pipeline Step 1:  [Component] Load data from BQ\n",
    "- Extracts training data from BQ table referenced as input to component\n",
    "- Loads data into Dataframe\n",
    "- Outputs data from component as CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497743d-f8ab-4d27-95c4-491ceb810857",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-bigquery\", \"pandas\", \"pyarrow\", \"db_dtypes\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    # output_component_file=\"create_dataset.yaml\"\n",
    "    )\n",
    "def get_dataframe(\n",
    "    bq_table: str,\n",
    "    output_data_path: OutputPath(\"Dataset\")\n",
    "    ):\n",
    "    from google.cloud import bigquery\n",
    "    import pandas as pd\n",
    "    bqclient = bigquery.Client(project=\"#PROJECT_ID HERE\")\n",
    "    table = bigquery.TableReference.from_string(\n",
    "        bq_table\n",
    "    )\n",
    "    rows = bqclient.list_rows(\n",
    "        table\n",
    "    )\n",
    "    dataframe = rows.to_dataframe(\n",
    "        create_bqstorage_client=True,\n",
    "    )\n",
    "    dataframe = dataframe.sample(frac=1, random_state=2)\n",
    "    dataframe.to_csv(output_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad76fec-c872-4381-850d-25fdac8eebb0",
   "metadata": {},
   "source": [
    "# Pipeline Step 2:  [Component] Train Scikit-learn model\n",
    "- Takes CSV data from step 1 as input\n",
    "- Train Scikit-learn decision tree model\n",
    "- Output model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6183165-3abe-4928-8b54-28016f330838",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"sklearn\", \"pandas\", \"joblib\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"beans_model_component.yaml\",\n",
    ")\n",
    "def sklearn_train(\n",
    "    dataset: Input[Dataset],\n",
    "    metrics: Output[Metrics],\n",
    "    model: Output[Model]\n",
    "):\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "    from sklearn.metrics import roc_curve\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from joblib import dump\n",
    "    import pandas as pd\n",
    "    df = pd.read_csv(dataset.path)\n",
    "    labels = df.pop(\"Class\").tolist()\n",
    "    data = df.values.tolist()\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, labels)\n",
    "    skmodel = DecisionTreeClassifier()\n",
    "    skmodel.fit(x_train,y_train)\n",
    "    score = skmodel.score(x_test,y_test)\n",
    "    print('accuracy is:',score)\n",
    "    metrics.log_metric(\"accuracy\",(score * 100.0))\n",
    "    metrics.log_metric(\"framework\", \"Scikit Learn\")\n",
    "    metrics.log_metric(\"dataset_size\", len(df))\n",
    "    dump(skmodel, model.path + \".joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a65c4e-3a22-4c29-849c-dcd9a5890c8d",
   "metadata": {},
   "source": [
    "# Pipeline Step 3:  [Component] Upload & Deploy model to Vertex AI\n",
    "- Takes model from step 2 as input\n",
    "- Upload model to Vertex AI\n",
    "- Deploy model as Vertex AI endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f993c9-dec1-4493-ab91-05ddbb022804",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    packages_to_install=[\"google-cloud-aiplatform\"],\n",
    "    base_image=\"python:3.9\",\n",
    "    output_component_file=\"beans_deploy_component.yaml\",\n",
    ")\n",
    "def deploy_model(\n",
    "    model: Input[Model],\n",
    "    project: str,\n",
    "    region: str,\n",
    "    vertex_endpoint: Output[Artifact],\n",
    "    vertex_model: Output[Model]\n",
    "):\n",
    "    from google.cloud import aiplatform\n",
    "    aiplatform.init(project=project, location=region)\n",
    "    deployed_model = aiplatform.Model.upload(\n",
    "        display_name=\"beans-model-pipeline\",\n",
    "        artifact_uri = model.uri.replace(\"model\", \"\"),\n",
    "        serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-24:latest\"\n",
    "    )\n",
    "    endpoint = deployed_model.deploy(machine_type=\"n1-standard-4\")\n",
    "    # Save data to the output params\n",
    "    vertex_endpoint.uri = endpoint.resource_name\n",
    "    vertex_model.uri = deployed_model.resource_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78976e47-291c-4660-907d-19ff15e42da8",
   "metadata": {},
   "source": [
    "# Pipeline Definition: Create a pipeline from the 3 components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9268c43-0974-43d4-8202-64a62e4462f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pipeline(\n",
    "    # Default pipeline root. You can override it when submitting the pipeline.\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    "    # A name for the pipeline.\n",
    "    name=\"mlmd-pipeline\",\n",
    ")\n",
    "def pipeline(\n",
    "    bq_table: str = \"\",\n",
    "    output_data_path: str = \"data.csv\",\n",
    "    project: str = PROJECT_ID,\n",
    "    region: str = REGION\n",
    "):\n",
    "    dataset_task = get_dataframe(bq_table)\n",
    "    model_task = sklearn_train(\n",
    "        dataset_task.output\n",
    "    )\n",
    "    deploy_task = deploy_model(\n",
    "        model=model_task.outputs[\"model\"],\n",
    "        project=project,\n",
    "        region=region\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0195d9da-b44a-4994-9407-6ef290320a10",
   "metadata": {},
   "source": [
    "# Compile pipeline to JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c6492e-3bf7-499d-a55f-e25ae537116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline, package_path=\"mlmd_pipeline.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ee694b-0a2b-4696-9566-c7c1fb194e2a",
   "metadata": {},
   "source": [
    "# Execute Pipeline Runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c20ae-91ce-4c84-b42a-c25590436e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "print(TIMESTAMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81b3bd1-6157-442f-a3fa-78c5aa693a3b",
   "metadata": {},
   "source": [
    "# Create Pipeline Job 1: Small Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd5fa22-df08-48f9-86b9-18f1f2d824e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1 = aiplatform.PipelineJob(\n",
    "    display_name=\"mlmd-pipeline\",\n",
    "    template_path=\"mlmd_pipeline.json\",\n",
    "    job_id=\"mlmd-pipeline-small-{0}\".format(TIMESTAMP),\n",
    "    parameter_values={\"bq_table\":\"{0}.beans.dry_bean_tbl_small\".format(PROJECT_ID)},\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6734541d-34f9-4932-bb23-309b4ee2a059",
   "metadata": {},
   "source": [
    "# Create Pipeline Job 2:  Full Dataset Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826ad9ed-3006-44b5-a7e8-ed6f555fec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "run2 = aiplatform.PipelineJob(\n",
    "    display_name=\"mlmd-pipeline\",\n",
    "    template_path=\"mlmd_pipeline.json\",\n",
    "    job_id=\"mlmd-pipeline-large-{0}\".format(TIMESTAMP),\n",
    "    parameter_values={\"bq_table\":\"{0}.beans.dry_bean_tbl\".format(PROJECT_ID)},\n",
    "    enable_caching=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990cf78-37d0-4922-be24-e087e470d23c",
   "metadata": {},
   "source": [
    "# Execute Jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fca55f-c90e-4fed-8713-0b4cbb15deb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "run1.submit()\n",
    "#run2.submit()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m97",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m97"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
